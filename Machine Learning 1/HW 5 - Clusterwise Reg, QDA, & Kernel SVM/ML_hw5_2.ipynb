{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = pd.read_csv(\"diabetes_train.csv\")\n",
    "df_test = pd.read_csv(\"diabetes_test.csv\")\n",
    "\n",
    "target_col = \"readmitted\"  \n",
    "X_train_full = df_train.drop(columns=[target_col])\n",
    "y_train_full = df_train[target_col]\n",
    "\n",
    "X_test = df_test.drop(columns=[target_col])\n",
    "y_test = df_test[target_col]\n",
    "\n",
    "cat_cols = X_train_full.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "X_train_full = pd.get_dummies(X_train_full, columns=cat_cols, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=cat_cols, drop_first=True)\n",
    "\n",
    "X_train_full, X_test = X_train_full.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "X_train_full = var_thresh.fit_transform(X_train_full)\n",
    "X_test = var_thresh.transform(X_test)\n",
    "\n",
    "X_train, _, y_train, _ = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    train_size=0.7,  \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_qda = qda_model.predict(X_train)\n",
    "y_pred_test_qda = qda_model.predict(X_test)\n",
    "\n",
    "print(\"=== QDA Results ===\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train_qda))\n",
    "print(\"Test Accuracy:    \", accuracy_score(y_test, y_pred_test_qda))\n",
    "print(\"\\nConfusion Matrix (Test):\\n\", confusion_matrix(y_test, y_pred_test_qda))\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred_test_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QDA Results ===\n",
      "Training Accuracy: 0.5378915599958373\n",
      "Test Accuracy:     0.5288278487897743\n",
      "\n",
      "Confusion Matrix (Test):\n",
      " [[    3    10  3240]\n",
      " [   18    42 10481]\n",
      " [   41    70 15511]]\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         <30       0.05      0.00      0.00      3253\n",
      "         >30       0.34      0.00      0.01     10541\n",
      "          NO       0.53      0.99      0.69     15622\n",
      "\n",
      "    accuracy                           0.53     29416\n",
      "   macro avg       0.31      0.33      0.23     29416\n",
      "weighted avg       0.41      0.53      0.37     29416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM (Linear + PCA + Balanced) Results ===\n",
      "Training Accuracy: 0.5208450411072952\n",
      "Test Accuracy:     0.5108784335055752\n",
      "\n",
      "Confusion Matrix (Test):\n",
      " [[  125     2  3126]\n",
      " [  288     4 10249]\n",
      " [  689    34 14899]]\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         <30       0.11      0.04      0.06      3253\n",
      "         >30       0.10      0.00      0.00     10541\n",
      "          NO       0.53      0.95      0.68     15622\n",
      "\n",
      "    accuracy                           0.51     29416\n",
      "   macro avg       0.25      0.33      0.25     29416\n",
      "weighted avg       0.33      0.51      0.37     29416\n",
      "\n",
      "\n",
      "QDA Test Accuracy: 0.5288278487897743\n",
      "SVM Test Accuracy: 0.5108784335055752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50, random_state=42)),\n",
    "    ('svm', SVC(kernel='linear', \n",
    "                C=1.0, \n",
    "                class_weight='balanced', \n",
    "                tol=1e-3, \n",
    "                max_iter=10000,\n",
    "                random_state=42))\n",
    "])\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_svm = svm_pipeline.predict(X_train)\n",
    "y_pred_test_svm = svm_pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\n=== SVM (Linear + PCA + Balanced) Results ===\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train_svm))\n",
    "print(\"Test Accuracy:    \", accuracy_score(y_test, y_pred_test_svm))\n",
    "print(\"\\nConfusion Matrix (Test):\\n\", confusion_matrix(y_test, y_pred_test_svm))\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred_test_svm))\n",
    "\n",
    "print(\"\\nQDA Test Accuracy:\", accuracy_score(y_test, y_pred_test_qda))\n",
    "print(\"SVM Test Accuracy:\", accuracy_score(y_test, y_pred_test_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing findings \n",
    "\n",
    "We see that our QDA accuracy is 52.9%, and the SVM accuracy is 51.1%. From this, we can state that QDA is marginally better than SVM, though both models didn't perform as well as intended. This might be due to the imbalanced dataset where very few datapoints were <30, and skewed results. With the current hyperparameter tunings, the model does not predict as well as expected and may not be best suited to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
