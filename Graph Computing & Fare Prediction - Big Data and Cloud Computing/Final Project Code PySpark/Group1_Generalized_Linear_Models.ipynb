{"cells": [{"cell_type": "code", "execution_count": 2, "id": "21879310-488a-49cd-8dc0-b8d542591d81", "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import PolynomialExpansion\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import PolynomialExpansion\nfrom pyspark.ml.regression import GeneralizedLinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.sql.functions import col"}, {"cell_type": "code", "execution_count": 3, "id": "29fd014e-b039-4332-92fd-3f71810f84bb", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\n\n# Initialize Spark session\nspark = SparkSession.builder \\\n    .appName(\"GAM\") \\\n    .getOrCreate()"}, {"cell_type": "markdown", "id": "392c5f93-993e-4342-ab83-71dd140b771d", "metadata": {}, "source": "### Loading Data"}, {"cell_type": "code", "execution_count": 4, "id": "294cf363-0748-4ea5-ab0a-d6af51641a70", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\n|               legId|searchDate|flightDate|travelDuration|elapsedDays|isRefundable|totalFare|seatsRemaining|DaysBeforeFlight|Layovers|NumStops|NumUniqueAirlines|AircraftType|NumUniqueCabins|hasFirstClass|FlightArrivalDate|totalTravelDistance|startingAirport_onehot|destinationAirport_onehot|AirlineName_0_onehot|AirlineName_1_onehot|AirlineName_2_onehot|AirlineName_3_onehot|AirlineName_4_onehot|    log_totalFare|\n+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\n|00000f65c6af0f881...|2022-05-25|2022-05-28|           185|          0|           0|   561.61|             5|               3|   [CLE]|       1|                1|           2|              1|            0|       2022-05-28|                649|       (15,[11],[1.0])|           (15,[7],[1.0])|      (13,[1],[1.0])|      (15,[3],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|6.330807658820878|\n|000019591cfd2d4eb...|2022-06-19|2022-08-03|           621|          0|           0|   257.21|             7|              45|   [AUS]|       1|                1|           1|              1|            0|       2022-08-03|               1876|       (15,[10],[1.0])|           (15,[8],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])| 5.54989287185648|\n|000019591cfd2d4eb...|2022-07-14|2022-08-03|           621|          0|           0|    337.2|             7|              20|   [AUS]|       1|                1|           1|              1|            0|       2022-08-03|               1876|       (15,[10],[1.0])|           (15,[8],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|  5.8206762261277|\n|00002b6f11d86964d...|2022-06-19|2022-08-13|           401|          0|           0|    792.6|             9|              55|   [DEN]|       1|                1|           3|              1|            0|       2022-08-13|               2373|        (15,[0],[1.0])|           (15,[9],[1.0])|      (13,[2],[1.0])|      (15,[2],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|6.675318680756335|\n|000030a6b191a05f3...|2022-06-12|2022-08-08|           137|          0|           0|    244.6|             7|              57|      []|       0|                1|           2|              1|            0|       2022-08-08|                725|        (15,[7],[1.0])|           (15,[2],[1.0])|      (13,[0],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.499624223253072|\n|000030a6b191a05f3...|2022-07-18|2022-08-08|           137|          0|           0|    192.6|             7|              21|      []|       0|                1|           2|              1|            0|       2022-08-08|                725|        (15,[7],[1.0])|           (15,[2],[1.0])|      (13,[0],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.260615499364025|\n|000032c98a1411929...|2022-09-14|2022-10-12|           142|          0|           0|     77.6|             9|              28|      []|       0|                1|           1|              1|            0|       2022-10-12|                848|        (15,[0],[1.0])|          (15,[10],[1.0])|      (13,[2],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|4.351567427189173|\n|000032c98a1411929...|2022-09-29|2022-10-12|           142|          0|           0|    178.6|             9|              13|      []|       0|                1|           1|              1|            0|       2022-10-12|                848|        (15,[0],[1.0])|          (15,[10],[1.0])|      (13,[2],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.185148668442398|\n|0000418a90646f46c...|2022-09-10|2022-09-23|           580|          0|           0|    338.6|             9|              13|   [ATL]|       1|                1|           3|              1|            0|       2022-09-23|               2659|       (15,[13],[1.0])|           (15,[0],[1.0])|      (13,[1],[1.0])|      (15,[3],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.824819469699035|\n|0000495bcccb2492d...|2022-08-17|2022-09-23|           289|          0|           0|    117.6|             1|              37|   [DCA]|       1|                1|           3|              1|            0|       2022-09-23|               1329|        (15,[8],[1.0])|           (15,[3],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|4.767289035464526|\n+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Load dataset \ntrain_path = \"gs://msca-bdp-student-gcs/Group1/lr_data/traindata_transformed/\"\ndf_train = spark.read.parquet(train_path, header=True, inferSchema=True)\n\ndf_train.show(10)"}, {"cell_type": "code", "execution_count": 5, "id": "190212b6-a13f-44d5-af27-ee7d79de20d2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 3:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\n|               legId|searchDate|flightDate|travelDuration|elapsedDays|isRefundable|totalFare|seatsRemaining|DaysBeforeFlight|Layovers|NumStops|NumUniqueAirlines|AircraftType|NumUniqueCabins|hasFirstClass|FlightArrivalDate|totalTravelDistance|startingAirport_onehot|destinationAirport_onehot|AirlineName_0_onehot|AirlineName_1_onehot|AirlineName_2_onehot|AirlineName_3_onehot|AirlineName_4_onehot|    log_totalFare|\n+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\n|00000f65c6af0f881...|2022-05-25|2022-05-28|           185|          0|           0|   561.61|             5|               3|   [CLE]|       1|                1|           2|              1|            0|       2022-05-28|                649|       (15,[11],[1.0])|           (15,[7],[1.0])|      (13,[1],[1.0])|      (15,[3],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|6.330807658820878|\n|000019591cfd2d4eb...|2022-06-19|2022-08-03|           621|          0|           0|   257.21|             7|              45|   [AUS]|       1|                1|           1|              1|            0|       2022-08-03|               1876|       (15,[10],[1.0])|           (15,[8],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])| 5.54989287185648|\n|000019591cfd2d4eb...|2022-07-14|2022-08-03|           621|          0|           0|    337.2|             7|              20|   [AUS]|       1|                1|           1|              1|            0|       2022-08-03|               1876|       (15,[10],[1.0])|           (15,[8],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|  5.8206762261277|\n|00002b6f11d86964d...|2022-06-19|2022-08-13|           401|          0|           0|    792.6|             9|              55|   [DEN]|       1|                1|           3|              1|            0|       2022-08-13|               2373|        (15,[0],[1.0])|           (15,[9],[1.0])|      (13,[2],[1.0])|      (15,[2],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|6.675318680756335|\n|000030a6b191a05f3...|2022-06-12|2022-08-08|           137|          0|           0|    244.6|             7|              57|      []|       0|                1|           2|              1|            0|       2022-08-08|                725|        (15,[7],[1.0])|           (15,[2],[1.0])|      (13,[0],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.499624223253072|\n|000030a6b191a05f3...|2022-07-18|2022-08-08|           137|          0|           0|    192.6|             7|              21|      []|       0|                1|           2|              1|            0|       2022-08-08|                725|        (15,[7],[1.0])|           (15,[2],[1.0])|      (13,[0],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.260615499364025|\n|000032c98a1411929...|2022-09-14|2022-10-12|           142|          0|           0|     77.6|             9|              28|      []|       0|                1|           1|              1|            0|       2022-10-12|                848|        (15,[0],[1.0])|          (15,[10],[1.0])|      (13,[2],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|4.351567427189173|\n|000032c98a1411929...|2022-09-29|2022-10-12|           142|          0|           0|    178.6|             9|              13|      []|       0|                1|           1|              1|            0|       2022-10-12|                848|        (15,[0],[1.0])|          (15,[10],[1.0])|      (13,[2],[1.0])|      (15,[0],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.185148668442398|\n|0000418a90646f46c...|2022-09-10|2022-09-23|           580|          0|           0|    338.6|             9|              13|   [ATL]|       1|                1|           3|              1|            0|       2022-09-23|               2659|       (15,[13],[1.0])|           (15,[0],[1.0])|      (13,[1],[1.0])|      (15,[3],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|5.824819469699035|\n|0000495bcccb2492d...|2022-08-17|2022-09-23|           289|          0|           0|    117.6|             1|              37|   [DCA]|       1|                1|           3|              1|            0|       2022-09-23|               1329|        (15,[8],[1.0])|           (15,[3],[1.0])|      (13,[0],[1.0])|      (15,[1],[1.0])|      (12,[0],[1.0])|       (6,[0],[1.0])|       (1,[0],[1.0])|4.767289035464526|\n+--------------------+----------+----------+--------------+-----------+------------+---------+--------------+----------------+--------+--------+-----------------+------------+---------------+-------------+-----------------+-------------------+----------------------+-------------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------------+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Load dataset \ntest_path = \"gs://msca-bdp-student-gcs/Group1/lr_data/testdata_transformed/\"\ndf_test = spark.read.parquet(train_path, header=True, inferSchema=True)\n\ndf_test.show(10)"}, {"cell_type": "markdown", "id": "151f5f27-fbd0-48e1-b7b9-eb95f4fff5a5", "metadata": {}, "source": "#### Repartitioning Data"}, {"cell_type": "code", "execution_count": 6, "id": "3b5a6f64-071b-4508-abf8-9031d33cbba6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "20\n"}], "source": "# Repartition train data\nnum = df_train.rdd.getNumPartitions()\nprint(num)\ndf_train = df_train.repartition(num)"}, {"cell_type": "code", "execution_count": 7, "id": "d66251d7-213c-484e-ba99-8f2992f1e735", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "20\n"}], "source": "# Repartition test data\nnum = df_test.rdd.getNumPartitions()\nprint(num)\ndf_test = df_test.repartition(num)"}, {"cell_type": "markdown", "id": "fb09632d-bec5-476a-948a-012f18eb6879", "metadata": {}, "source": "### Baseline Model"}, {"cell_type": "code", "execution_count": 27, "id": "cb9c5e17-8ae7-4074-a416-38321e4cfb63", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|            features|       poly_features|\n+--------------------+--------------------+\n|[3.0,1.0,1.0,1.0,...|[3.0,9.0,27.0,81....|\n|[45.0,1.0,1.0,1.0...|[45.0,2025.0,9112...|\n|[20.0,1.0,1.0,1.0...|[20.0,400.0,8000....|\n|[55.0,1.0,1.0,1.0...|[55.0,3025.0,1663...|\n|[57.0,0.0,1.0,1.0...|[57.0,3249.0,1851...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "# Assemble features into a single vector column\n\nfeature_columns = [\n    \"DaysBeforeFlight\", \"NumStops\", \"NumUniqueAirlines\", \"NumUniqueCabins\", \n    \"travelDuration\", \"isRefundable\", \"hasFirstClass\", \"totalTravelDistance\",\n    \"AircraftType\", \"seatsRemaining\", \"elapsedDays\"\n]\n\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf = assembler.transform(df_train)\n\n# Apply polynomial expansion to degree 4\npoly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=4)\n\ndf = poly_expansion.transform(df)\n\ndf.select(\"features\", \"poly_features\").show(5)\n"}, {"cell_type": "code", "execution_count": 28, "id": "afe558d1-235e-44ee-8f16-d918ba725eb2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 02:45:13 WARN org.apache.spark.ml.util.Instrumentation: [fb4683da] regParam is zero, which might cause numerical instability and overfitting.\n24/12/02 03:12:55 WARN org.apache.spark.ml.util.Instrumentation: [fb4683da] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"}], "source": "# Prepare the data for GLM\ndf2 = df.withColumn(\"target\", df[\"log_totalFare\"])  \ndf2 = df2.drop(\"features\")\ndf2 = df2.withColumnRenamed(\"poly_features\", \"features\") \n\n# Create and fit the GLM model (using Gaussian family and identity link)\nglm = GeneralizedLinearRegression(featuresCol=\"features\", labelCol=\"target\", family=\"gaussian\", link=\"identity\")\n\n# Fit the model\nmodel = glm.fit(df2)"}, {"cell_type": "code", "execution_count": 29, "id": "e1dda10c-c7f4-4ad5-a7a5-485bbdca9ec4", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 38:==================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "R^2:  0.43175539395783724\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Make predictions\npredictions = model.transform(df2)\n\n# Initialize the evaluator to compute R2\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"r2\")\n\n# Calculate R\u00b2\nr2 = evaluator.evaluate(predictions)\nprint(\"R^2: \", r2)"}, {"cell_type": "code", "execution_count": 30, "id": "cc6b2969-4d12-4e09-b112-75b51c970da1", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 40:=====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE:  0.43585079012796013\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Initialize the evaluator to compute RMSE\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# Calculate RMSE\nrmse = evaluator.evaluate(predictions)\nprint(\"RMSE: \", rmse)"}, {"cell_type": "markdown", "id": "fdf13287-5ffc-4bd5-a6fa-54abbce39f2c", "metadata": {}, "source": "### Model with Backwards Elimination Features"}, {"cell_type": "code", "execution_count": 26, "id": "d86a49ca-6720-41ae-bb0e-c43225c7a319", "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import col\n\n# Create interaction term between number\ndf_train = df_train.withColumn(\"NumUniqueCabins_hasFirstClass\", col(\"NumUniqueCabins\") * col(\"hasFirstClass\"))\n\n# Update feature_columns to include interaction terms\nfeature_columns = [\n    'travelDuration','elapsedDays', 'isRefundable', 'seatsRemaining', 'DaysBeforeFlight', \n    'NumStops', 'NumUniqueAirlines', 'AircraftType', 'NumUniqueCabins', \n    'hasFirstClass','startingAirport_onehot', 'destinationAirport_onehot',\n    'AirlineName_0_onehot', 'NumUniqueCabins_hasFirstClass'\n]"}, {"cell_type": "code", "execution_count": 27, "id": "78927990-d497-4391-8dfb-d0d44cbdb117", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|            features|       poly_features|\n+--------------------+--------------------+\n|(54,[0,3,4,5,6,7,...|(1539,[0,1,9,10,1...|\n|(54,[0,3,4,5,6,7,...|(1539,[0,1,9,10,1...|\n|(54,[0,3,4,5,6,7,...|(1539,[0,1,9,10,1...|\n|(54,[0,3,4,5,6,7,...|(1539,[0,1,9,10,1...|\n|(54,[0,3,4,6,7,8,...|(1539,[0,1,9,10,1...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf = assembler.transform(df_train)\n\n# Apply polynomial expansion with degre 4\npoly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=2)\n\ndf = poly_expansion.transform(df)\n\n# Show the transformed features\ndf.select(\"features\", \"poly_features\").show(5)"}, {"cell_type": "code", "execution_count": 28, "id": "4954fa81-6148-4426-a35f-810e43a8a2ea", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 18:56:07 WARN org.apache.spark.ml.util.Instrumentation: [0f252abe] regParam is zero, which might cause numerical instability and overfitting.\n24/12/02 18:59:22 WARN org.apache.spark.ml.util.Instrumentation: [0f252abe] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"}], "source": "# Prepare the data for GLM\ndf2 = df.withColumn(\"target\", df[\"log_totalFare\"])  \ndf2 = df2.drop(\"features\")\ndf2 = df2.withColumnRenamed(\"poly_features\", \"features\")  \n\n# Create and fit the GLM model (using Gaussian family and identity link)\nglm = GeneralizedLinearRegression(featuresCol=\"features\", labelCol=\"target\", family=\"gaussian\", link=\"identity\")\n\n# Fit the model\nmodel = glm.fit(df2)"}, {"cell_type": "code", "execution_count": 29, "id": "312b399f-3e0b-4aa2-90f1-73802228f2fd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 34:=====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "R^2:  0.576656509774735\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Make predictions\npredictions = model.transform(df2)\n\n# Initialize the evaluator to compute R2\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"r2\")\n\n# Calculate R\u00b2 \nr2 = evaluator.evaluate(predictions)\nprint(\"R^2: \", r2)"}, {"cell_type": "code", "execution_count": null, "id": "a797bd5d-a023-4a09-8be1-60c7c13022df", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 36:=====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE:  0.37619811892184796\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Initialize the evaluator to compute RMSE\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# Calculate RMSE\nrmse = evaluator.evaluate(predictions)\nprint(\"RMSE: \", rmse)"}, {"cell_type": "code", "execution_count": null, "id": "1d36da4d-5a5e-4d0e-ac99-a1b1db5c9cc7", "metadata": {}, "outputs": [], "source": "# Create interaction terms\ndf_test = df_test.withColumn(\"NumUniqueCabins_hasFirstClass\", col(\"NumUniqueCabins\") * col(\"hasFirstClass\"))\n\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf = assembler.transform(df_test)\n\n# Apply polynomial expansion with degree 2\npoly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=2)\n\ndf = poly_expansion.transform(df)\n\n# Prepare the data for GLM\ndf2 = df.withColumn(\"target\", df[\"log_totalFare\"])  \ndf2 = df2.drop(\"features\")\ndf2 = df2.withColumnRenamed(\"poly_features\", \"features\")  "}, {"cell_type": "code", "execution_count": null, "id": "4f2ae7a1-593a-409d-a8df-fa7179568827", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 38:=====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Test RMSE:  0.37619811892184796\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Make predictions\npredictions = model.transform(df2)\n\n# Initialize the evaluator to compute RMSE\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# Calculate RMSE\nrmse = evaluator.evaluate(predictions)\nprint(\"Test RMSE: \", rmse)"}, {"cell_type": "markdown", "id": "cb8b633f-a165-4800-a627-c17a9c937058", "metadata": {}, "source": "### Model with Forward Selection Features"}, {"cell_type": "code", "execution_count": 15, "id": "41f4b71b-dab8-4836-a2ca-0e0327599e80", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|            features|       poly_features|\n+--------------------+--------------------+\n|(30,[0,1,13,18],[...|(495,[0,1,2,3,4,1...|\n|(30,[0,1,12,17],[...|(495,[0,1,2,3,4,9...|\n|(30,[0,1,12,17],[...|(495,[0,1,2,3,4,9...|\n|(30,[0,1,2,19],[2...|(495,[0,1,2,3,4,5...|\n|(30,[0,1,9,17],[7...|(495,[0,1,2,3,4,5...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "# Assemble features into a single vector column\nfeature_columns = [\"totalTravelDistance\",\"NumUniqueAirlines\",\"startingAirport_onehot\", \n                   'AirlineName_0_onehot']\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf = assembler.transform(df_train)\n\n\npoly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=2)\n\ndf = poly_expansion.transform(df)\n\n# Show the transformed features\ndf.select(\"features\", \"poly_features\").show(5)\n"}, {"cell_type": "code", "execution_count": 16, "id": "66f0e209-b5d7-4924-aa90-c79da8d89945", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 18:31:40 WARN org.apache.spark.ml.util.Instrumentation: [c27ee27e] regParam is zero, which might cause numerical instability and overfitting.\n24/12/02 18:32:28 WARN org.apache.spark.ml.util.Instrumentation: [c27ee27e] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"}], "source": "# Prepare the data for GLM\ndf2 = df.withColumn(\"target\", df[\"log_totalFare\"])  \ndf2 = df2.drop(\"features\")\ndf2 = df2.withColumnRenamed(\"poly_features\", \"features\") \n\n# Create and fit the GLM model \nglm = GeneralizedLinearRegression(featuresCol=\"features\", labelCol=\"target\", family=\"gaussian\", link=\"identity\")\n\n# Fit the model\nmodel = glm.fit(df2)"}, {"cell_type": "code", "execution_count": 17, "id": "43dc10af-829c-4b1f-80f5-507443dce82c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 18:==================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "R^2:  0.4578508208764329\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.evaluation import RegressionEvaluator\n\n# Make predictions\npredictions = model.transform(df2)\n\n# Initialize the evaluator\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"r2\")\n\n# Calculate R\u00b2 manually\nr2 = evaluator.evaluate(predictions)\nprint(\"R^2: \", r2)"}, {"cell_type": "code", "execution_count": 18, "id": "c36b8bd9-18fd-4d39-be12-7882c535d778", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 20:=====================================================>  (19 + 1) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE:  0.4257254163841886\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Initialize the evaluator to compute RMSE\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# Calculate RMSE\nrmse = evaluator.evaluate(predictions)\nprint(\"RMSE: \", rmse)"}, {"cell_type": "markdown", "id": "e2d06900-4c54-4961-a017-efe33e462f4d", "metadata": {}, "source": "#### Perfomance testing with test df"}, {"cell_type": "code", "execution_count": 19, "id": "a4035001-4271-47cd-b4c1-3a2fcf28a7d5", "metadata": {}, "outputs": [], "source": "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndf = assembler.transform(df_test)\n\n# Apply polynomial expansion \npoly_expansion = PolynomialExpansion(inputCol=\"features\", outputCol=\"poly_features\", degree=2)\n\ndf = poly_expansion.transform(df)\n\n# Prepare the data for GLM\ndf2 = df.withColumn(\"target\", df[\"log_totalFare\"])  \ndf2 = df2.drop(\"features\")\ndf2 = df2.withColumnRenamed(\"poly_features\", \"features\")  "}, {"cell_type": "code", "execution_count": 20, "id": "3ca607db-0d55-492f-902a-daa3baf19163", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 22:==================================================>     (18 + 2) / 20]\r"}, {"name": "stdout", "output_type": "stream", "text": "Test RMSE:  0.42572541638418865\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Make predictions\npredictions = model.transform(df2)\n\n# Initialize the evaluator to compute RMSE\nevaluator = RegressionEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"rmse\")\n\n# Calculate RMSE\nrmse = evaluator.evaluate(predictions)\nprint(\"Test RMSE: \", rmse)"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}